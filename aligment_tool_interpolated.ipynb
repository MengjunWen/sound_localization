{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "\n",
    "def detect_position(image, mtx, dist):\n",
    "    x = 250  # Side length of the square\n",
    "    pts_known = np.array([[-x/2, -x/2], [x/2, -x/2], [x/2, x/2], [-x/2, x/2]], dtype='float32')\n",
    "    frame_width = image.shape[1]\n",
    "    frame_height = image.shape[0]\n",
    "\n",
    "    # Define the ArUco marker dictionary\n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "\n",
    "    frame = image\n",
    "\n",
    "    # Convert to grayscale for marker detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ArUco markers\n",
    "    detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "    corners, ids, _ = detector.detectMarkers(gray)\n",
    "\n",
    "    # if ids is not None:\n",
    "    #     img = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    #     for corner in corners:\n",
    "    #         center = np.mean(corner[0], axis=0)\n",
    "    #         cv2.circle(img, tuple(center.astype(int)), 5, (0, 255, 0), -1)  # Draw a circle at the center of the marker\n",
    "\n",
    "    # cv2.imshow('ArUco Markers', img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    if ids is not None:\n",
    "        \n",
    "        ids = ids.flatten()  # Flatten to a 1D array\n",
    "        if len(ids) < 5:\n",
    "            return None\n",
    "        pts_detected = np.zeros((4, 2), dtype='float32')\n",
    "        for i, marker_id in enumerate([0, 1, 2, 3]):\n",
    "            idx = np.where(ids == marker_id)[0][0]\n",
    "            pts_detected[i] = np.mean(corners[idx][0], axis=0)\n",
    "        \n",
    "        # Compute homography matrix\n",
    "        H, _ = cv2.findHomography(pts_known, pts_detected)\n",
    "\n",
    "        virtual_points = []\n",
    "        # Process each detected marker\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            if marker_id != 4:\n",
    "                continue\n",
    "            c = corners[i][0]\n",
    "            center = np.mean(c, axis=0)\n",
    "            # Transform marker coordinates to virtual plane\n",
    "            pts_img = np.array([[center[0], center[1]]], dtype='float32')\n",
    "            \n",
    "            return cv2.perspectiveTransform(np.array([pts_img]), np.linalg.inv(H))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bd04b5b68246af99924537b614dbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Subfolders:', options=('exp_1', 'exp_10', 'exp_11', 'exp_12', 'exp_13', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera parameters not found. Using default values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 219.\n",
      "No ArUco marker detected in frame 220.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 1142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 1216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 1314.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 1374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ArUco marker detected in frame 1379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location data saved to experiments\\exp_1\\location_data.csv.\n",
      "Missing frame data saved to experiments\\exp_1\\missing_data_info.csv.\n",
      "Interpolated location data saved to experiments\\exp_1\\interpolated_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Video, HTML\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# --- Global Variables ---\n",
    "current_frame = 0\n",
    "cap = None\n",
    "video_path = None\n",
    "total_frames = 0\n",
    "fps = 30  # Default FPS\n",
    "start_frame = 50\n",
    "stop_frame = 100\n",
    "mtx = None # Placeholder for camera matrix\n",
    "dist = None # Placeholder for distortion coefficients\n",
    "\n",
    "experiments_folder = 'experiments'\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_frame(frame_num, cap):\n",
    "    \"\"\"Reads a specific frame from the video.\"\"\"\n",
    "    global total_frames\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame or end of video.\")\n",
    "        return None\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    _, encoded_frame = cv2.imencode('.jpg', frame)\n",
    "    return encoded_frame.tobytes()\n",
    "\n",
    "def update_video_display(frame_data, video_widget):\n",
    "    \"\"\"Updates the displayed video frame.\"\"\"\n",
    "    video_widget.value = frame_data\n",
    "    with current_frame_output:\n",
    "        current_frame_output.clear_output(wait=True)\n",
    "        display(format_frame_info(current_frame, fps))\n",
    "\n",
    "def format_frame_info(frame_num, fps):\n",
    "    \"\"\"Formats frame number and time information.\"\"\"\n",
    "    if fps > 0:  # Avoid division by zero\n",
    "        seconds = frame_num / fps\n",
    "        return f\"Frame: {frame_num} ({seconds:.2f}s)\"\n",
    "    else:\n",
    "        return f\"Frame: {frame_num} (FPS not available)\"\n",
    "\n",
    "def save_location_data_with_missing_info(location_data, folder_path, missing_data_info, interpolated_data):\n",
    "    \"\"\"Saves the location data, including missing frame information, to CSV.\"\"\"\n",
    "    \n",
    "    # 确保文件夹存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # 保存位置数据\n",
    "    location_csv_path = os.path.join(folder_path, 'location_data.csv')\n",
    "    missing_info_csv_path = os.path.join(folder_path, 'missing_data_info.csv')\n",
    "    interpolated_csv_path = os.path.join(folder_path, 'interpolated_data.csv')\n",
    "    \n",
    "    # 保存位置数据\n",
    "    with open(location_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Frame Number', 'X', 'Y'])\n",
    "        for frame_num, loc in location_data:\n",
    "            if loc is not None and isinstance(loc, np.ndarray) and loc.shape[-1] == 2:\n",
    "                x = loc[0][0][0]  # 从loc中提取x坐标\n",
    "                y = loc[0][0][1]  # 从loc中提取y坐标\n",
    "                writer.writerow([frame_num, x, y])\n",
    "            else:\n",
    "                print(f\"Invalid location data for frame {frame_num}: {loc}\")\n",
    "    \n",
    "    print(f\"Location data saved to {location_csv_path}.\")\n",
    "    \n",
    "    # 保存缺失数据的信息\n",
    "    with open(missing_info_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Frame Number', 'Status', 'Fill Method'])\n",
    "        for frame_num, fill_method in missing_data_info:\n",
    "            writer.writerow([frame_num, 'Missing', fill_method])\n",
    "    print(f\"Missing frame data saved to {missing_info_csv_path}.\")\n",
    "    \n",
    "    # 保存插值后的数据\n",
    "    with open(interpolated_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Frame Number', 'X', 'Y'])\n",
    "        for frame_num, loc in interpolated_data:\n",
    "            if loc is not None and isinstance(loc, np.ndarray) and loc.shape[-1] == 2:\n",
    "                x = loc[0][0][0]  # 从loc中提取x坐标\n",
    "                y = loc[0][0][1]  # 从loc中提取y坐标\n",
    "                writer.writerow([frame_num, x, y])\n",
    "            else:\n",
    "                print(f\"Invalid interpolated data for frame {frame_num}: {loc}\")\n",
    "    \n",
    "    print(f\"Interpolated location data saved to {interpolated_csv_path}.\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_missing_frames(location_data, missing_frames):\n",
    "    interpolated_data = list(location_data)  # 初始化为原始数据\n",
    "\n",
    "    for frame_num in missing_frames:\n",
    "        # 找到前后有效的帧\n",
    "        prev_frame = next((f for f in reversed(location_data) if f[0] < frame_num), None)\n",
    "        next_frame = next((f for f in location_data if f[0] > frame_num), None)\n",
    "\n",
    "        if prev_frame and next_frame:\n",
    "            prev_num, prev_loc = prev_frame\n",
    "            next_num, next_loc = next_frame\n",
    "\n",
    "            # 解包嵌套数据\n",
    "            prev_loc = np.squeeze(np.array(prev_loc))\n",
    "            next_loc = np.squeeze(np.array(next_loc))\n",
    "\n",
    "            # 确保是 1D 数组\n",
    "            if prev_loc.ndim == 1 and next_loc.ndim == 1:\n",
    "                # 计算线性插值\n",
    "                ratio = (frame_num - prev_num) / (next_num - prev_num)\n",
    "                interpolated_loc = prev_loc + ratio * (next_loc - prev_loc)\n",
    "\n",
    "                # 将插值结果添加到数据中\n",
    "                interpolated_data.append((frame_num, np.array([[interpolated_loc]])))\n",
    "        elif prev_frame:  # 只有前帧有效\n",
    "            interpolated_data.append((frame_num, np.array(prev_frame[1])))\n",
    "        elif next_frame:  # 只有后帧有效\n",
    "            interpolated_data.append((frame_num, np.array(next_frame[1])))\n",
    "\n",
    "    # 按帧号排序\n",
    "    interpolated_data = sorted(interpolated_data, key=lambda x: x[0])\n",
    "    \n",
    "    return interpolated_data\n",
    "\n",
    "\n",
    "# --- UI Elements ---\n",
    "# Get all subfolders\n",
    "subfolders = [f.name for f in os.scandir(experiments_folder) if f.is_dir()]\n",
    "\n",
    "# Dropdown\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=subfolders,\n",
    "    description='Subfolders:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Video Widget\n",
    "video_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "\n",
    "# Current Frame Display\n",
    "current_frame_output = widgets.Output()\n",
    "\n",
    "# Buttons\n",
    "forward_button = widgets.Button(description=\">>\")\n",
    "backward_button = widgets.Button(description=\"<<\")\n",
    "forward_1s_button = widgets.Button(description=\"> 1s\")\n",
    "backward_1s_button = widgets.Button(description=\"< 1s\")\n",
    "forward_60s_button = widgets.Button(description=\"> 60s\")\n",
    "backward_60s_button = widgets.Button(description=\"< 60s\")\n",
    "load_button = widgets.Button(description=\"Load Video\")\n",
    "start_frame_button = widgets.Button(description=\"Set Start\")\n",
    "stop_frame_button = widgets.Button(description=\"Set Stop\")\n",
    "transform_frame_button = widgets.Button(description=\"Transform Image\")\n",
    "extract_location_button = widgets.Button(description=\"Extract Location\")\n",
    "# Output for Start/Stop Frame Information\n",
    "start_frame_output = widgets.Output()\n",
    "stop_frame_output = widgets.Output()\n",
    "\n",
    "# --- Event Handlers ---\n",
    "\n",
    "def on_load_clicked(b):\n",
    "    \"\"\"Loads the video.\"\"\"\n",
    "    global cap, video_path, current_frame, fps, total_frames, start_frame, stop_frame, mtx, dist\n",
    "    current_frame = 0\n",
    "    start_frame = 50\n",
    "    stop_frame = 1500\n",
    "    \n",
    "    files = [f.name for f in os.scandir(os.path.join(experiments_folder, dropdown.value)) if f.is_file()]\n",
    "    video_file = next((f for f in files if f.endswith('.mp4')), None)\n",
    "\n",
    "    if video_file:\n",
    "        video_path = os.path.join(experiments_folder, dropdown.value, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error opening video.\")\n",
    "            return\n",
    "        \n",
    "        # Load camera parameters if available\n",
    "        param_file = os.path.join(experiments_folder, dropdown.value, 'c922_params.npz')\n",
    "        if os.path.exists(param_file):\n",
    "            data = np.load(param_file)\n",
    "            mtx, dist = data['mtx'], data['dist']\n",
    "        else:\n",
    "            print(\"Camera parameters not found. Using default values.\")\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        initial_frame = get_frame(current_frame, cap)\n",
    "        if initial_frame:\n",
    "            update_video_display(initial_frame, video_widget)\n",
    "\n",
    "        # Reset start/stop frame info\n",
    "        with start_frame_output:\n",
    "            start_frame_output.clear_output()\n",
    "            print(format_frame_info(start_frame, fps))\n",
    "        with stop_frame_output:\n",
    "            stop_frame_output.clear_output()\n",
    "            print(format_frame_info(stop_frame, fps))\n",
    "\n",
    "    else:\n",
    "        video_path = None\n",
    "        print('No video file found.')\n",
    "\n",
    "def on_forward_clicked(b):\n",
    "    \"\"\"Moves forward by one frame.\"\"\"\n",
    "    global current_frame, total_frames\n",
    "    if cap and current_frame < total_frames - 1:\n",
    "        current_frame += 1\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_backward_clicked(b):\n",
    "    \"\"\"Moves backward by one frame.\"\"\"\n",
    "    global current_frame\n",
    "    if cap and current_frame > 0:\n",
    "        current_frame -= 1\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_forward_1s_clicked(b):\n",
    "    \"\"\"Moves forward by 1 second.\"\"\"\n",
    "    global current_frame, fps, total_frames\n",
    "    if cap:\n",
    "        current_frame += int(fps)\n",
    "        current_frame = min(current_frame, total_frames - 1)\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_backward_1s_clicked(b):\n",
    "    \"\"\"Moves backward by 1 second.\"\"\"\n",
    "    global current_frame, fps\n",
    "    if cap:\n",
    "        current_frame -= int(fps)\n",
    "        current_frame = max(current_frame, 0)\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_forward_60s_clicked(b):\n",
    "    \"\"\"Moves forward by 60 seconds.\"\"\"\n",
    "    global current_frame, fps, total_frames\n",
    "    if cap:\n",
    "        current_frame += int(fps * 60)\n",
    "        current_frame = min(current_frame, total_frames - 1)\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_backward_60s_clicked(b):\n",
    "    \"\"\"Moves backward by 60 seconds.\"\"\"\n",
    "    global current_frame, fps\n",
    "    if cap:\n",
    "        current_frame -= int(fps * 60)\n",
    "        current_frame = max(current_frame, 0)\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            update_video_display(frame_data, video_widget)\n",
    "\n",
    "def on_start_frame_clicked(b):\n",
    "    \"\"\"Sets the start frame.\"\"\"\n",
    "    global start_frame\n",
    "    start_frame = current_frame\n",
    "    with start_frame_output:\n",
    "        start_frame_output.clear_output()\n",
    "        print(format_frame_info(start_frame, fps))\n",
    "\n",
    "def on_stop_frame_clicked(b):\n",
    "    \"\"\"Sets the stop frame.\"\"\"\n",
    "    global stop_frame\n",
    "    stop_frame = current_frame\n",
    "    with stop_frame_output:\n",
    "        stop_frame_output.clear_output()\n",
    "        print(format_frame_info(stop_frame, fps))\n",
    "\n",
    "def on_transform_image_clicked(b):\n",
    "    \"\"\"Transforms the image.\"\"\"\n",
    "    global current_frame\n",
    "    if cap:\n",
    "        frame_data = get_frame(current_frame, cap)\n",
    "        if frame_data:\n",
    "            frame = cv2.imdecode(np.frombuffer(frame_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "            center_location = detect_position(frame, mtx, dist)\n",
    "            if center_location is not None:\n",
    "                _, encoded_frame = cv2.imencode('.jpg', frame)\n",
    "                update_video_display(encoded_frame.tobytes(), video_widget)\n",
    "\n",
    "def on_extract_location_with_missing_info_clicked(b):\n",
    "    \"\"\"Extracts the location of the sound source and interpolates missing frame info.\"\"\"\n",
    "    global current_frame, start_frame, stop_frame\n",
    "    \n",
    "    folder_path = os.path.join(experiments_folder, dropdown.value)\n",
    "    # Ensure the folder exists (create if it doesn't)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    location_data = []  # 存储帧的位置信息\n",
    "    missing_data_info = []  # 存储缺失帧信息\n",
    "    missing_frames = []  # 记录所有缺失的帧号\n",
    "\n",
    "    if cap:\n",
    "        for frame_num in range(start_frame, stop_frame + 1):\n",
    "            current_frame = frame_num\n",
    "            frame_data = get_frame(current_frame, cap)\n",
    "            if frame_data:\n",
    "                frame = cv2.imdecode(np.frombuffer(frame_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "                center_location = detect_position(frame, mtx, dist)\n",
    "\n",
    "                if center_location is not None:\n",
    "                    _, encoded_frame = cv2.imencode('.jpg', frame)\n",
    "                    update_video_display(encoded_frame.tobytes(), video_widget)\n",
    "                    location_data.append((frame_num, center_location))\n",
    "                else:\n",
    "                    print(f\"No ArUco marker detected in frame {frame_num}.\")\n",
    "                    missing_frames.append(frame_num)\n",
    "                    missing_data_info.append((frame_num, 'Linear Interpolation'))  # 标记补充方法\n",
    "\n",
    "    # 对缺失帧进行线性插值\n",
    "    interpolated_data = []\n",
    "    if missing_frames:\n",
    "        interpolated_data = interpolate_missing_frames(location_data, missing_frames)\n",
    "\n",
    "    # 调用保存函数时传入插值后的数据\n",
    "    save_location_data_with_missing_info(location_data, folder_path, missing_data_info, interpolated_data)     \n",
    "\n",
    "def on_extract_location_clicked(b):\n",
    "    \"\"\"Extracts the location of the sound source.\"\"\"\n",
    "    global current_frame, start_frame, stop_frame\n",
    "    location_data = []\n",
    "    missing_data_info = []  # 初始化缺失数据补充信息列表\n",
    "    \n",
    "    # Get the folder path based on dropdown selection\n",
    "    folder_path = os.path.join(experiments_folder, dropdown.value)\n",
    "\n",
    "    # Ensure the folder exists (create if it doesn't)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    if cap:\n",
    "        for frame_num in range(start_frame, stop_frame + 1):\n",
    "            current_frame = frame_num\n",
    "            frame_data = get_frame(current_frame, cap)\n",
    "            if frame_data:\n",
    "                frame = cv2.imdecode(np.frombuffer(frame_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "                center_location = detect_position(frame, mtx, dist)\n",
    "                if center_location is not None:\n",
    "                    _, encoded_frame = cv2.imencode('.jpg', frame)\n",
    "                    update_video_display(encoded_frame.tobytes(), video_widget)\n",
    "                    location_data.append((frame_num, center_location))\n",
    "                else:\n",
    "                    print(f\"No ArUco marker detected in frame {frame_num}.\")\n",
    "    \n",
    "    # Save the location data to a CSV file in the current folder\n",
    "    if len(location_data) > 0:\n",
    "        location_csv_path = os.path.join(folder_path, 'location_data.csv')\n",
    "        with open(location_csv_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Frame Number', 'X', 'Y'])\n",
    "            for frame_num, loc in location_data:\n",
    "                x = loc[0][0][0]  # Access the x coordinate\n",
    "                y = loc[0][0][1]  # Access the y coordinate\n",
    "                writer.writerow([frame_num, x, y])\n",
    "        print(f\"Location data saved to {location_csv_path}.\")\n",
    "\n",
    "    print(\"Location data:\", location_data)\n",
    " \n",
    "# --- Attach Event Handlers ---\n",
    "\n",
    "load_button.on_click(on_load_clicked)\n",
    "forward_button.on_click(on_forward_clicked)\n",
    "backward_button.on_click(on_backward_clicked)\n",
    "forward_1s_button.on_click(on_forward_1s_clicked)\n",
    "backward_1s_button.on_click(on_backward_1s_clicked)\n",
    "forward_60s_button.on_click(on_forward_60s_clicked)\n",
    "backward_60s_button.on_click(on_backward_60s_clicked)\n",
    "start_frame_button.on_click(on_start_frame_clicked)\n",
    "stop_frame_button.on_click(on_stop_frame_clicked)\n",
    "transform_frame_button.on_click(on_transform_image_clicked)\n",
    "extract_location_button.on_click(on_extract_location_with_missing_info_clicked)\n",
    "\n",
    "# --- Layout ---\n",
    "\n",
    "buttons_60s = widgets.HBox([backward_60s_button, forward_60s_button])\n",
    "buttons_1s = widgets.HBox([backward_1s_button, forward_1s_button])\n",
    "buttons_frames = widgets.HBox([backward_button, forward_button])\n",
    "buttons_start_stop = widgets.HBox([start_frame_button, stop_frame_button])\n",
    "info_layout = widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Start Frame:\"), start_frame_output]),\n",
    "    widgets.VBox([widgets.Label(\"Stop Frame:\"), stop_frame_output]),\n",
    "])\n",
    "\n",
    "ui_layout = widgets.VBox([\n",
    "    dropdown,\n",
    "    load_button,\n",
    "    video_widget,\n",
    "    current_frame_output,\n",
    "    buttons_60s,\n",
    "    buttons_1s,\n",
    "    buttons_frames,\n",
    "    buttons_start_stop,\n",
    "    info_layout,\n",
    "    transform_frame_button,\n",
    "    extract_location_button,\n",
    "])\n",
    "\n",
    "display(ui_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_1\\recorded_20241219_185715_177641.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_1\\recorded_20241219_185715_177641.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_10\\recorded_20241220_135643_142996.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_10\\recorded_20241220_135643_142996.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_11\\recorded_20241220_140020_852143.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_11\\recorded_20241220_140020_852143.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_12\\recorded_20241220_140730_724828.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_12\\recorded_20241220_140730_724828.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_13\\recorded_20241220_141533_753456.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_13\\recorded_20241220_141533_753456.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_14\\recorded_20241220_142702_650383.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_14\\recorded_20241220_142702_650383.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_14_with_noise\\recorded_20241220_141901_897120.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_14_with_noise\\recorded_20241220_141901_897120.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_15\\recorded_20241220_143048_530595.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_15\\recorded_20241220_143048_530595.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_16\\recorded_20241220_141205_430570.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_16\\recorded_20241220_141205_430570.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_2\\recorded_20241219_190555_944658.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_2\\recorded_20241219_190555_944658.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_3\\recorded_20241219_191218_158041.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_3\\recorded_20241219_191218_158041.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_4\\recorded_20241219_191712_881132.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_4\\recorded_20241219_191712_881132.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_5\\recorded_20241219_192351_918878.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_5\\recorded_20241219_192351_918878.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_6\\recorded_20241219_192807_335965.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_6\\recorded_20241219_192807_335965.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_7\\recorded_20241219_194647_135310.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_7\\recorded_20241219_194647_135310.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_8\\recorded_20241219_195309_036637.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_8\\recorded_20241219_195309_036637.mp4\n",
      "Successfully converted D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_9\\recorded_20241220_135200_494866.avi to D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\exp_9\\recorded_20241220_135200_494866.mp4\n",
      "Processed .avi files:\n",
      "{'exp_1': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_1\\\\recorded_20241219_185715_177641.avi', 'exp_10': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_10\\\\recorded_20241220_135643_142996.avi', 'exp_11': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_11\\\\recorded_20241220_140020_852143.avi', 'exp_12': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_12\\\\recorded_20241220_140730_724828.avi', 'exp_13': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_13\\\\recorded_20241220_141533_753456.avi', 'exp_14': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_14\\\\recorded_20241220_142702_650383.avi', 'exp_14_with_noise': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_14_with_noise\\\\recorded_20241220_141901_897120.avi', 'exp_15': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_15\\\\recorded_20241220_143048_530595.avi', 'exp_16': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_16\\\\recorded_20241220_141205_430570.avi', 'exp_2': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_2\\\\recorded_20241219_190555_944658.avi', 'exp_3': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_3\\\\recorded_20241219_191218_158041.avi', 'exp_4': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_4\\\\recorded_20241219_191712_881132.avi', 'exp_5': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_5\\\\recorded_20241219_192351_918878.avi', 'exp_6': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_6\\\\recorded_20241219_192807_335965.avi', 'exp_7': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_7\\\\recorded_20241219_194647_135310.avi', 'exp_8': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_8\\\\recorded_20241219_195309_036637.avi', 'exp_9': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_9\\\\recorded_20241220_135200_494866.avi'}\n",
      "Generated .mp4 files:\n",
      "{'exp_1': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_1\\\\recorded_20241219_185715_177641.mp4', 'exp_10': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_10\\\\recorded_20241220_135643_142996.mp4', 'exp_11': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_11\\\\recorded_20241220_140020_852143.mp4', 'exp_12': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_12\\\\recorded_20241220_140730_724828.mp4', 'exp_13': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_13\\\\recorded_20241220_141533_753456.mp4', 'exp_14': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_14\\\\recorded_20241220_142702_650383.mp4', 'exp_14_with_noise': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_14_with_noise\\\\recorded_20241220_141901_897120.mp4', 'exp_15': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_15\\\\recorded_20241220_143048_530595.mp4', 'exp_16': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_16\\\\recorded_20241220_141205_430570.mp4', 'exp_2': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_2\\\\recorded_20241219_190555_944658.mp4', 'exp_3': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_3\\\\recorded_20241219_191218_158041.mp4', 'exp_4': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_4\\\\recorded_20241219_191712_881132.mp4', 'exp_5': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_5\\\\recorded_20241219_192351_918878.mp4', 'exp_6': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_6\\\\recorded_20241219_192807_335965.mp4', 'exp_7': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_7\\\\recorded_20241219_194647_135310.mp4', 'exp_8': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_8\\\\recorded_20241219_195309_036637.mp4', 'exp_9': 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments\\\\exp_9\\\\recorded_20241220_135200_494866.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Get all subfolders in the \"experiments\" folder\n",
    "experiments_folder = 'D:/MOOD-SENSE/sound_localization-no_multicast_to_esp32/experiments'  # Adjust the path as needed\n",
    "subfolders = [f.name for f in os.scandir(experiments_folder) if f.is_dir()]\n",
    "\n",
    "avi_files = {}\n",
    "mp4_files = {}\n",
    "\n",
    "# Process each subfolder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(experiments_folder, subfolder)\n",
    "    files = [f.name for f in os.scandir(subfolder_path) if f.is_file()]\n",
    "\n",
    "    # Find the first .avi file in the subfolder\n",
    "    avi_file = next((f for f in files if f.endswith('.avi')), None)\n",
    "    if avi_file is None:\n",
    "        print(f\"No .avi file found in {subfolder_path}\")\n",
    "        continue\n",
    "\n",
    "    avi_file_path = os.path.join(subfolder_path, avi_file)\n",
    "    output_file_path = os.path.splitext(avi_file_path)[0] + '.mp4'\n",
    "\n",
    "    # Run ffmpeg command\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'D:\\\\MOOD-SENSE\\\\ffmpeg-master-latest-win64-gpl-shared\\\\bin\\\\ffmpeg.exe',\n",
    "            '-i', avi_file_path,\n",
    "            '-ac', '2',\n",
    "            '-b:v', '2000k',\n",
    "            '-c:a', 'aac',\n",
    "            '-c:v', 'libx264',\n",
    "            '-b:a', '160k',\n",
    "            '-vprofile', 'high',\n",
    "            '-f', 'mp4',\n",
    "            output_file_path\n",
    "        ], check=True)\n",
    "        avi_files[subfolder] = avi_file_path\n",
    "        mp4_files[subfolder] = output_file_path\n",
    "        print(f\"Successfully converted {avi_file_path} to {output_file_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting {avi_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in {subfolder}: {e}\")\n",
    "\n",
    "# Log results\n",
    "print(\"Processed .avi files:\")\n",
    "print(avi_files)\n",
    "print(\"Generated .mp4 files:\")\n",
    "print(mp4_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
